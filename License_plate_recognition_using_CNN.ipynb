{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5fnU5oI2kKD7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Dropout, Conv2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plate_cascade = cv2.CascadeClassifier('path_to_file/indian_license_plate.xml')"
      ],
      "metadata": {
        "id": "e5N77Jf5kah2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Load the cascade classifier\n",
        "plate_cascade = cv2.CascadeClassifier('path_to_file/indian_license_plate.xml')"
      ],
      "metadata": {
        "id": "Bs04FvHnq0Oq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_plate(img, text=''): # the function detects and perfors blurring on the number plate.\n",
        "    plate_img = img.copy()\n",
        "    roi = img.copy()\n",
        "    plate_rect = plate_cascade.detectMultiScale(plate_img, scaleFactor = 1.2, minNeighbors = 7) # detects numberplates and returns the coordinates and dimensions of detected license plate's contours.\n",
        "    for (x,y,w,h) in plate_rect:\n",
        "        roi_ = roi[y:y+h, x:x+w, :] # extracting the Region of Interest of license plate for blurring.\n",
        "        plate = roi[y:y+h, x:x+w, :]\n",
        "        cv2.rectangle(plate_img, (x+2,y), (x+w-3, y+h-5), (51,181,155), 3) # finally representing the detected contours by drawing rectangles around the edges.\n",
        "    if text!='':\n",
        "        plate_img = cv2.putText(plate_img, text, (x-w//2,y-h//2),\n",
        "                                cv2.FONT_HERSHEY_COMPLEX_SMALL , 0.5, (51,181,155), 1, cv2.LINE_AA)\n",
        "\n",
        "    return plate_img, plate # returning the processed image."
      ],
      "metadata": {
        "id": "j4OQk_o3nyca"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display(img_, title=''):\n",
        "    img = cv2.cvtColor(img_, cv2.COLOR_BGR2RGB)\n",
        "    fig = plt.figure(figsize=(10,6))\n",
        "    ax = plt.subplot(111)\n",
        "    ax.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "img = cv2.imread('/content/car.jpg')\n",
        "display(img, 'input image')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "SAnnALPUoSn2",
        "outputId": "bcb98506-cd88-45f9-80c3-a6568da52d16"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c19ed9fbf3fa>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/car.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input image'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-c19ed9fbf3fa>\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(img_, title)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Load the trained cascade classifier\n",
        "cascade_path = 'indian_license_plate.xml'  # Replace with your XML file path\n",
        "plate_cascade = cv2.CascadeClassifier(cascade_path)\n",
        "\n",
        "# Read the image\n",
        "image_path = '/content/car.jpg'  # Replace with your image file path\n",
        "img = cv2.imread(image_path)\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Perform license plate detection\n",
        "plates = plate_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "# Draw rectangles around detected license plates\n",
        "for (x, y, w, h) in plates:\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "\n",
        "# Display the result\n",
        "cv2_imshow(img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "EDHxni4Oo9zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "F076CTRMbP4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_img, plate = detect_plate(img)"
      ],
      "metadata": {
        "id": "SuXMDZBfuEWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(output_img, 'detected license plate in the input image')"
      ],
      "metadata": {
        "id": "orYojqyAuwHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(plate, 'extracted license plate from the image')"
      ],
      "metadata": {
        "id": "7Sglx63luy8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_contours(dimensions, img) :\n",
        "\n",
        "    # Find all contours in the image\n",
        "    cntrs, _ = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Retrieve potential dimensions\n",
        "    lower_width = dimensions[0]\n",
        "    upper_width = dimensions[1]\n",
        "    lower_height = dimensions[2]\n",
        "    upper_height = dimensions[3]\n",
        "\n",
        "    # Check largest 5 or  15 contours for license plate or character respectively\n",
        "    cntrs = sorted(cntrs, key=cv2.contourArea, reverse=True)[:15]\n",
        "\n",
        "    ii = cv2.imread('contour.jpg')\n",
        "\n",
        "    x_cntr_list = []\n",
        "    target_contours = []\n",
        "    img_res = []\n",
        "    for cntr in cntrs :\n",
        "        # detects contour in binary image and returns the coordinates of rectangle enclosing it\n",
        "        intX, intY, intWidth, intHeight = cv2.boundingRect(cntr)\n",
        "\n",
        "        # checking the dimensions of the contour to filter out the characters by contour's size\n",
        "        if intWidth > lower_width and intWidth < upper_width and intHeight > lower_height and intHeight < upper_height :\n",
        "            x_cntr_list.append(intX) #stores the x coordinate of the character's contour, to used later for indexing the contours\n",
        "\n",
        "            char_copy = np.zeros((44,24))\n",
        "            # extracting each character using the enclosing rectangle's coordinates.\n",
        "            char = img[intY:intY+intHeight, intX:intX+intWidth]\n",
        "            char = cv2.resize(char, (20, 40))\n",
        "\n",
        "            cv2.rectangle(ii, (intX,intY), (intWidth+intX, intY+intHeight), (50,21,200), 2)\n",
        "            plt.imshow(ii, cmap='gray')\n",
        "\n",
        "            # Make result formatted for classification: invert colors\n",
        "            char = cv2.subtract(255, char)\n",
        "\n",
        "            # Resize the image to 24x44 with black border\n",
        "            char_copy[2:42, 2:22] = char\n",
        "            char_copy[0:2, :] = 0\n",
        "            char_copy[:, 0:2] = 0\n",
        "            char_copy[42:44, :] = 0\n",
        "            char_copy[:, 22:24] = 0\n",
        "\n",
        "            img_res.append(char_copy) # List that stores the character's binary image (unsorted)\n",
        "\n",
        "    # Return characters on ascending order with respect to the x-coordinate (most-left character first)\n",
        "\n",
        "    plt.show()\n",
        "    # arbitrary function that stores sorted list of character indeces\n",
        "    indices = sorted(range(len(x_cntr_list)), key=lambda k: x_cntr_list[k])\n",
        "    img_res_copy = []\n",
        "    for idx in indices:\n",
        "        img_res_copy.append(img_res[idx])# stores character images according to their index\n",
        "    img_res = np.array(img_res_copy)\n",
        "\n",
        "    return img_res"
      ],
      "metadata": {
        "id": "Cgq0rsaTu8TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find characters in the resulting images\n",
        "def segment_characters(image) :\n",
        "\n",
        "    # Preprocess cropped license plate image\n",
        "    img_lp = cv2.resize(image, (333, 75))\n",
        "    img_gray_lp = cv2.cvtColor(img_lp, cv2.COLOR_BGR2GRAY)\n",
        "    _, img_binary_lp = cv2.threshold(img_gray_lp, 200, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    img_binary_lp = cv2.erode(img_binary_lp, (3,3))\n",
        "    img_binary_lp = cv2.dilate(img_binary_lp, (3,3))\n",
        "\n",
        "    LP_WIDTH = img_binary_lp.shape[0]\n",
        "    LP_HEIGHT = img_binary_lp.shape[1]\n",
        "\n",
        "    # Make borders white\n",
        "    img_binary_lp[0:3,:] = 255\n",
        "    img_binary_lp[:,0:3] = 255\n",
        "    img_binary_lp[72:75,:] = 255\n",
        "    img_binary_lp[:,330:333] = 255\n",
        "\n",
        "    # Estimations of character contours sizes of cropped license plates\n",
        "    dimensions = [LP_WIDTH/6,\n",
        "                       LP_WIDTH/2,\n",
        "                       LP_HEIGHT/10,\n",
        "                       2*LP_HEIGHT/3]\n",
        "    plt.imshow(img_binary_lp, cmap='gray')\n",
        "    plt.show()\n",
        "    cv2.imwrite('contour.jpg',img_binary_lp)\n",
        "\n",
        "    # Get contours within cropped license plate\n",
        "    char_list = find_contours(dimensions, img_binary_lp)\n",
        "\n",
        "    return char_list"
      ],
      "metadata": {
        "id": "8v4TjCGVvCbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see the segmented characters\n",
        "char = segment_characters(plate)"
      ],
      "metadata": {
        "id": "EHan4TNFvJxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(char[i], cmap='gray')\n",
        "    plt.axis('off')\n"
      ],
      "metadata": {
        "id": "wQfwgCDBvMUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model for characters**"
      ],
      "metadata": {
        "id": "tN22OIHNvVHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, width_shift_range=0.1, height_shift_range=0.1)\n",
        "path = '/content/drive/MyDrive/data/data'\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        path+'/train',  # this is the target directory\n",
        "        target_size=(28,28),  # all images will be resized to 28x28\n",
        "        batch_size=1,\n",
        "        class_mode='sparse')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        path+'/val',  # this is the target directory\n",
        "        target_size=(28,28),  # all images will be resized to 28x28 batch_size=1,\n",
        "        class_mode='sparse')"
      ],
      "metadata": {
        "id": "jXydZpzWvQTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics for checking the model performance while training\n",
        "def f1score(y, y_pred):\n",
        "  return f1_score(y, tf.math.argmax(y_pred, axis=1), average='micro')\n",
        "\n",
        "def custom_f1score(y, y_pred):\n",
        "  return tf.py_function(f1score, (y, y_pred), tf.double)"
      ],
      "metadata": {
        "id": "84stlrFdwSLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (22,22), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(32, (16,16), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (8,8), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (4,4), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(36, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.Adam(lr=0.0001), metrics=[custom_f1score])"
      ],
      "metadata": {
        "id": "cyAUSP46wZge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "muBdJPkKwe6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class stop_training_callback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_custom_f1score') > 0.99):\n",
        "      self.model.stop_training = True"
      ],
      "metadata": {
        "id": "lMgbZ3WowlKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "callbacks = [stop_training_callback()]\n",
        "model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch = train_generator.samples // batch_size,\n",
        "      validation_data = validation_generator,\n",
        "      epochs = 80, verbose=1, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "OO7lJFLiwqkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_dimension(img):\n",
        "  new_img = np.zeros((28, 28, 3))\n",
        "  for i in range(3):\n",
        "    new_img[:,:,i] = img\n",
        "  return new_img\n",
        "\n",
        "def show_results():\n",
        "    dic = {}\n",
        "    characters = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "    for i, c in enumerate(characters):\n",
        "        dic[i] = c\n",
        "\n",
        "    output = []\n",
        "    for i, ch in enumerate(char):  # iterating over the characters\n",
        "        img_ = cv2.resize(ch, (28, 28), interpolation=cv2.INTER_AREA)\n",
        "        img = fix_dimension(img_)\n",
        "        img = img.reshape(1, 28, 28, 3)  # preparing image for the model\n",
        "        y_prob = model.predict(img)[0]  # predicting probabilities for each class\n",
        "        y_class = np.argmax(y_prob)  # finding the class with the highest probability\n",
        "        character = dic[y_class]\n",
        "        output.append(character)  # storing the result in a list\n",
        "\n",
        "    plate_number = ''.join(output)\n",
        "\n",
        "    return plate_number\n",
        "\n",
        "print(show_results())\n"
      ],
      "metadata": {
        "id": "kDzjtaRAwtBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segmented characters and their predicted value.\n",
        "plt.figure(figsize=(10,6))\n",
        "for i,ch in enumerate(char):\n",
        "    img = cv2.resize(ch, (28,28), interpolation=cv2.INTER_AREA)\n",
        "    plt.subplot(3,4,i+1)\n",
        "    plt.imshow(img,cmap='gray')\n",
        "    plt.title(f'predicted: {show_results()[i]}')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XCfyEywCxI9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w1-gC6CWPw2n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}